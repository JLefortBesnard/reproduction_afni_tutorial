

import nipype
import nipype.interfaces.afni as afni


print("auto-generated by afni_proc.py, Tue Jan 31 15:45:04 2023")
print("(version 7.51, January 24, 2023)")
print("execution started: `date`")


# =========================== auto block: setup ============================
# script setup


# assign sub and output directory name
sub = 'FT'
output_dir = 'FT.results'
# set list of runs
runs = [1, 2, 3]

# create results and stimuli directories
import pathlib
from os.path import join as opj
pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)
pathlib.Path(opj(output_dir, 'stimuli')).mkdir(parents=True, exist_ok=True)

# copy stim files into stimulus directory
import shutil
src1 = opj(sub, "AV1_vis.txt") 
src2 = opj(sub, "AV2_aud.txt")
dst = opj(output_dir, "stimuli")
shutil.copy(src1, dst)
shutil.copy(src2, dst)

# copy anatomy to results dir
copy3d= afni.Copy()
copy3d.inputs.in_file = "FT/FT_anat+orig.HEAD"
copy3d.inputs.out_file = opj(output_dir, "FT_anat")
copy3d.cmdline
# should be 
# 3dcopy FT/FT_anat+orig $output_dir/FT_anat
res = copy3d.run()

# copy template to results dir (for QC)
copy3d= afni.Copy()
copy3d.inputs.in_file = "/home/jlefortb/abin/TT_N27+tlrc.HEAD"
copy3d.inputs.out_file = opj(output_dir, "TT_N27+tlrc.HEAD")
copy3d.cmdline
# should be 
# 3dcopy /home/jlefortb/abin/TT_N27+tlrc.HEAD $output_dir/TT_N27+tlrc.HEAD
res = copy3d.run()

# ============================ auto block: tcat ============================
# apply 3dTcat to copy input dsets to results dir,
# while removing the first 2 TRs
for run in runs:
	tcsb = afni.TCatSubBrick()
	tcsb.inputs.in_files = [('FT/FT_epi_r{}+orig.BRIK'.format(run), "'{2..$}'")]
	tcsb.inputs.out_file = opj(output_dir, "pb00.{}.r0{}.tcat".format(sub, run))
	tcsb.cmdline
	# should be
	# 3dTcat -prefix $output_dir/pb00.$subj.r01.tcat FT/FT_epi_r1+orig'[2..$]'
	res = tcsb.run()  

# and make note of repetitions (TRs) per run
tr_counts = [150, 150, 150]

# -------------------------------------------------------
# enter the results directory (can begin processing data)
from os import chdir
chdir(output_dir)

"""missing

# ---------------------------------------------------------
# QC: compute correlations with spherical ~averages
@radial_correlate -nfirst 0 -polort 3 -do_clean yes \
                  -rdir radcor.pb00.tcat            \
                  pb00.$subj.r*.tcat+orig.HEAD

# ---------------------------------------------------------
# QC: look for columns of high variance
find_variance_lines.tcsh -polort 3 -nerode 2        \
       -rdir vlines.pb00.tcat                       \
       pb00.$subj.r*.tcat+orig.HEAD |& tee out.vlines.pb00.tcat.txt
"""

# ========================== auto block: outcount ==========================
# QC: compute outlier fraction for each volume


for run in runs:
	toutcount = afni.OutlierCount(automask=True, fraction=True, polort=3, legendre=True)
	toutcount.inputs.in_file = 'pb00.{}.r0{}.tcat+orig.BRIK'.format(sub, run)
	toutcount.inputs.out_file = 'outcount.r0{}.1D'.format(run)
	toutcount.cmdline
	# should be
	# 3dToutcount -automask -fraction -polort 3 -legendre                     \
    #			pb00.$subj.r$run.tcat+orig > outcount.r$run.1D
	res = toutcount.run()


	"""missing
	1deval -a outcount.r$run.1D -expr "1-step(a-0.05)" > rm.out.cen.r$run.1D

    # outliers at TR 0 might suggest pre-steady state TRs
    if ( `1deval -a outcount.r$run.1D"{0}" -expr "step(a-0.4)"` ) then
        echo "** TR #0 outliers: possible pre-steady state TRs in run $run" \
            >> out.pre_ss_warn.txt
    """

# catenate outlier counts into a single time series
filenames = ['outcount.r01.1D', 'outcount.r02.1D', 'outcount.r03.1D']
with open('outcount_rall.1D', 'w') as outfile:
    for fname in filenames:
        with open(fname) as infile:
            outfile.write(infile.read())

"""missing
# catenate outlier censor files into a single time series
cat rm.out.cen.r*.1D > outcount_${subj}_censor.1D


"""

# get run number and TR index for minimum outlier volume
tstat = afni.TStat()
tstat.inputs.in_file = 'outcount_rall.1D'
tstat.inputs.args = '-argmin'
tstat.inputs.out_file = 'stats'
tstat.cmdline
minindex = tstat.run()



"""missing

set ovals = ( `1d_tool.py -set_run_lengths $tr_counts                       \
                          -index_to_run_tr $minindex` )
# save run and TR indices for extraction of vr_base_min_outlier
set minoutrun = $ovals[1]
set minouttr  = $ovals[2]
echo "min outlier: run $minoutrun, TR $minouttr" | tee out.min_outlier.txt


### first attempt :
odt = afni.OneDToolPy()
odt.inputs.args = "-set_run_lengths {}".format(tr_counts)
odt.inputs.args = "-index_to_run_tr {}".format(minindex)  
odt.inputs.set_run_lengths = tr_counts
odt.cmdline
res = odt.run()  # doctest: +SKIP

"""



# ================================= tshift =================================
# time shift data so all slice timing is the same 
for run in runs:
	tshift = afni.TShift()
	tshift.inputs.args = '-quintic'
	tshift.inputs.in_file = 'pb00.{}.r0{}.tcat+orig.BRIK'.format(sub, run)
	tshift.inputs.tzero = 0
	tshift.inputs.out_file = 'pb01.{}.r0{}.tshift+orig.BRIK'.format(sub, run)
	tshift.cmdline
    # should be 3dTshift -tzero 0 -quintic -prefix pb01.$subj.r$run.tshift \
    #         pb00.$subj.r$run.tcat+orig
	res = tshift.run()


# --------------------------------
# extract volreg registration base
bucket = afni.Bucket()
bucket.inputs.in_file = [('pb01.{}.r{}minoutrun.tshift+orig.BRIK'.format(sub, minoutrun),"[{}}]".format(minouttr))]
bucket.inputs.out_file = 'vr_base_min_outlier'
bucket.cmdline
# should be
# 3dbucket -prefix vr_base_min_outlier                           \
#     pb01.$subj.r$minoutrun.tshift+orig"[$minouttr]"
res = bucket.run()  # doctest: +SKIP




# ================================= align ==================================
# for e2a: compute anat alignment transformation to EPI registration base
# (new anat will be intermediate, stripped, FT_anat_ns+orig)
# run (localized) uniformity correction on EPI base

"""missing
3dLocalUnifize -input vr_base_min_outlier+orig -prefix \
    vr_base_min_outlier_unif
"""

al_ea = afni.AlignEpiAnatPy()
al_ea.inputs.anat = "FT_anat+orig"
al_ea.inputs.in_file = "vr_base_min_outlier_unif+orig"
al_ea.inputs.epi_base = 0
al_ea.inputs.args = "-cost lpc+ZZ -giant_move -check_flip"
al_ea.inputs.anat2epi = True
al_ea.inputs.suffix = "_al_junk"
al_ea.inputs.epi_strip = '3dAutomask'
al_ea.inputs.volreg = 'off'
al_ea.inputs.tshift = 'off'
al_ea.inputs.save_skullstrip = True
al_ea.cmdline
# should be
# align_epi_anat.py -anat2epi -anat FT_anat+orig         \
#        -save_skullstrip -suffix _al_junk               \
#        -epi vr_base_min_outlier_unif+orig -epi_base 0  \
#        -epi_strip 3dAutomask                           \
#        -cost lpc+ZZ -giant_move -check_flip            \
#        -volreg off -tshift off
res = allineate.run()  # doctest: +SKIP


# ================================== tlrc ==================================
# warp anatomy to standard space
autoTLRC = afni.AutoTLRC()
autoTLRC.inputs.in_file = 'FT_anat_ns+orig'
autoTLRC.inputs.no_ss = True
autoTLRC.inputs.base = "TT_N27+tlrc"
autoTLRC.cmdline
# should be
# @auto_tlrc -base TT_N27+tlrc -input FT_anat_ns+orig -no_ss
res = autoTLRC.run()


# store forward transformation matrix in a text file
cmv = afni.CatMatvec()
cmv.inputs.in_file = [('FT_anat_ns+tlrc::WARP_DATA','I')]
cmv.inputs.out_file = 'warp.anat.Xat.1D'
cmv.cmdline
# should be
# cat_matvec FT_anat_ns+tlrc::WARP_DATA -I > warp.anat.Xat.1D
res = cmv.run()

# ================================= volreg =================================
# align each dset to base volume, to anat, warp to tlrc space

# verify that we have a +tlrc warp dataset
from os.path import exists
assert exists("FT_anat_ns+tlrc.HEAD"), "** missing +tlrc warp dataset: FT_anat_ns+tlrc.HEAD"

# register and warp
for run in runs:
    # register each volume to the base image
    volreg = afni.Volreg()
    volreg.inputs.in_file = 'pb01.$subj.r$run.tshift+orig'
    volreg.inputs.interp = 'cubic'
    volreg.inputs.args = '-Fourier -twopass'
    volreg.inputs.verbose = True
    volreg.inputs.zpad = 1
    volreg.inputs.basefile = 'vr_base_min_outlier+orig'
    volreg.inputs.out_file = 'rm.epi.volreg.r{}'.format(run)
    volreg.inputs.oned_file = 'dfile.r{}.1D'.format(run)
    volreg.inputs.oned_matrix_save = 'mat.r{}.vr.aff12.1D'.format(run)
    volreg.cmdline
    # should be 
    # 3dvolreg -verbose -zpad 1 -base vr_base_min_outlier+orig    \
    #      -1Dfile dfile.r$run.1D -prefix rm.epi.volreg.r$run \
    #      -cubic                                             \
    #      -1Dmatrix_save mat.r$run.vr.aff12.1D               \
    #      pb01.$subj.r$run.tshift+orig
    res = volreg.run()

    # create an all-1 dataset to mask the extents of the warp
    calc = afni.Calc()
    calc.inputs.overwrite = True
    calc.inputs.in_file_a = 'pb01.{}.r{}.tshift+orig'.format(sub, run)
    calc.inputs.expr = 1
    calc.inputs.out_file = 'rm.epi.all1'
    calc.cmdline
    # should be
    # 3dcalc -overwrite -a pb01.$subj.r$run.tshift+orig -expr 1   \
    #        -prefix rm.epi.all1
    res = calc.run()

    # catenate volreg/epi2anat/tlrc xforms
    cmv = afni.CatMatvec()
    cmv.inputs.in_file = [('FT_anat_ns+tlrc::WARP_DATA','I'), ('FT_anat_al_junk_mat.aff12.1D','I')]
    cmv.inputs.out_file = 'mat.r$run.warp.aff12.1D'
    cmv.inputs.oneline = True
    cmv.cmdline
    # should be
    # cat_matvec -ONELINE                                         \
    #            FT_anat_ns+tlrc::WARP_DATA -I                    \
    #            FT_anat_al_junk_mat.aff12.1D -I                  \
    #            mat.r$run.vr.aff12.1D > mat.r$run.warp.aff12.1D
    res = cmv.run()

    # apply catenated xform: volreg/epi2anat/tlrc
    allineate = afni.Allineate()
    allineate.args = '-mast_dxyz 2.5'
    allineate.reference = 'FT_anat_ns+tlrc'
    allineate.inputs.in_file = 'pb01.{}.r{}.tshift+orig'.format(sub, run)
    allineate.inputs.in_matrix = 'mat.r{}.warp.aff12.1D'.format(run)
    allineate.inputs.out_file = 'rm.epi.nomask.r{}'.format(run)
    allineate.cmdline
    # should be
    # 3dAllineate -base FT_anat_ns+tlrc                           \
    #             -input pb01.$subj.r$run.tshift+orig             \
    #             -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
    #             -mast_dxyz 2.5                                  \
    #             -prefix rm.epi.nomask.r$run
    res = allineate.run()

    # warp the all-1 dataset for extents masking 
    allineate = afni.Allineate()
    allineate.args = '-final NN -mast_dxyz 2.5'
    allineate.quiet = True
    allineate.reference = 'FT_anat_ns+tlrc'
    allineate.inputs.in_file = 'rm.epi.all1+orig'
    allineate.inputs.in_matrix = 'mat.r{}.warp.aff12.1D'.format(run)
    allineate.inputs.out_file = 'rm.epi.1.r{}'.format(run)
    allineate.cmdline
    # should be
    # 3dAllineate -base FT_anat_ns+tlrc                           \
    #             -input rm.epi.all1+orig                         \
    #             -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
    #             -mast_dxyz 2.5 -final NN -quiet                 \
    #             -prefix rm.epi.1.r$run
    res = allineate.run()

    # make an extents intersection mask of this run
    tstat = afni.TStat()
    tstat.inputs.in_file = 'rm.epi.1.r{}+tlrc'.format(run)
    tstat.inputs.args = '-min'
    tstat.inputs.out_file = 'm.epi.min.r{}'.format(run)
    tstat.cmdline
    # should be
    # 3dTstat -min -prefix rm.epi.min.r$run rm.epi.1.r$run+tlrc
    res = tstat.run()


# make a single file of registration params
cat dfile.r*.1D > dfile_rall.1D

# catenate outlier counts into a single time series
filenames = ['dfile.r01.1D', 'dfile.r02.1D', 'dfile.r03.1D']
with open('outcount_{}_censor.1D'.format(sub), 'w') as outfile:
    for fname in filenames:
        with open(fname) as infile:
            outfile.write(infile.read())


# ----------------------------------------
# create the extents mask: mask_epi_extents+tlrc
# (this is a mask of voxels that have valid data at every TR)
from nipype.interfaces import afni
means = afni.Means()
means.datum = 'short'
means.inputs.in_file_a = 'rm.epi.min.r*.HEAD'
means.inputs.out_file =  'rm.epi.mean'
means.cmdline
# should be
# 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD 
res = means.run() 

calc = afni.Calc()
calc.inputs.in_file_a = 'rm.epi.mean+tlrc'
calc.inputs.expr='step(a-0.999)'
calc.inputs.out_file =  'mask_epi_extents'
calc.cmdline  # doctest: +ELLIPSIS
# should be
# 3dcalc -a rm.epi.mean+tlrc -expr 'step(a-0.999)' -prefix mask_epi_extents
res = calc.run()  # doctest: +SKIP


# and apply the extents mask to the EPI data 
# (delete any time series with missing data)
for run in runs:
    calc = afni.Calc()
    calc.inputs.in_file_a = 'rm.epi.nomask.r{}+tlrc'.format(run)
    calc.inputs.in_file_b = 'mask_epi_extents+tlrc'
    calc.inputs.expr='a*b'
    calc.inputs.out_file =  'pb02.{}.r{}.volreg'.format(sub, run)
    calc.cmdline  # doctest: +ELLIPSIS
    # should be
    # 3dcalc -a rm.epi.nomask.r$run+tlrc -b mask_epi_extents+tlrc \
    #        -expr 'a*b' -prefix pb02.$subj.r$run.volreg
    res = calc.run()  # doctest: +SKIP


# warp the volreg base EPI dataset to make a final version
cat_matvec -ONELINE                                             \
           FT_anat_ns+tlrc::WARP_DATA -I                        \
           FT_anat_al_junk_mat.aff12.1D -I  > mat.basewarp.aff12.1D

3dAllineate -base FT_anat_ns+tlrc                               \
            -input vr_base_min_outlier+orig                     \
            -1Dmatrix_apply mat.basewarp.aff12.1D               \
            -mast_dxyz 2.5                                      \
            -prefix final_epi_vr_base_min_outlier

# create an anat_final dataset, aligned with stats
3dcopy FT_anat_ns+tlrc anat_final.$subj

# record final registration costs
3dAllineate -base final_epi_vr_base_min_outlier+tlrc -allcostX  \
            -input anat_final.$subj+tlrc |& tee out.allcostX.txt

# --------------------------------------
# create a TSNR dataset, just from run 1
3dTstat -mean -prefix rm.signal.vreg.r01 pb02.$subj.r01.volreg+tlrc
3dDetrend -polort 3 -prefix rm.noise.det -overwrite pb02.$subj.r01.volreg+tlrc
3dTstat -stdev -prefix rm.noise.vreg.r01 rm.noise.det+tlrc
3dcalc -a rm.signal.vreg.r01+tlrc                               \
       -b rm.noise.vreg.r01+tlrc                                \
       -c mask_epi_extents+tlrc                                 \
       -expr 'c*a/b' -prefix TSNR.vreg.r01.$subj

# -----------------------------------------
# warp anat follower datasets (affine)
# warp follower dataset FT_anat+orig
3dAllineate -source FT_anat+orig                                \
            -master anat_final.$subj+tlrc                       \
            -final wsinc5 -1Dmatrix_apply warp.anat.Xat.1D      \
            -prefix anat_w_skull_warped

# ---------------------------------------------------------
# QC: compute correlations with spherical ~averages
@radial_correlate -nfirst 0 -polort 3 -do_clean yes             \
                  -rdir radcor.pb02.volreg                      \
                  pb02.$subj.r*.volreg+tlrc.HEAD

# ================================== blur ==================================
# blur each volume of each run
foreach run ( $runs )
    3dmerge -1blur_fwhm 4.0 -doall -prefix pb03.$subj.r$run.blur \
            pb02.$subj.r$run.volreg+tlrc
end

# ================================== mask ==================================
# create 'full_mask' dataset (union mask)
foreach run ( $runs )
    3dAutomask -prefix rm.mask_r$run pb03.$subj.r$run.blur+tlrc
end

# create union of inputs, output type is byte
3dmask_tool -inputs rm.mask_r*+tlrc.HEAD -union -prefix full_mask.$subj

# ---- create subject anatomy mask, mask_anat.$subj+tlrc ----
#      (resampled from tlrc anat)
3dresample -master full_mask.$subj+tlrc -input FT_anat_ns+tlrc        \
           -prefix rm.resam.anat

# convert to binary anat mask; fill gaps and holes
3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.anat+tlrc  \
            -prefix mask_anat.$subj

# compute tighter EPI mask by intersecting with anat mask
3dmask_tool -input full_mask.$subj+tlrc mask_anat.$subj+tlrc          \
            -inter -prefix mask_epi_anat.$subj

# compute overlaps between anat and EPI masks
3dABoverlap -no_automask full_mask.$subj+tlrc mask_anat.$subj+tlrc    \
            |& tee out.mask_ae_overlap.txt

# note Dice coefficient of masks, as well
3ddot -dodice full_mask.$subj+tlrc mask_anat.$subj+tlrc               \
      |& tee out.mask_ae_dice.txt

# ---- create group anatomy mask, mask_group+tlrc ----
#      (resampled from tlrc base anat, TT_N27+tlrc)
3dresample -master full_mask.$subj+tlrc -prefix ./rm.resam.group      \
           -input /home/jlefortb/abin/TT_N27+tlrc

# convert to binary group mask; fill gaps and holes
3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.group+tlrc \
            -prefix mask_group

# note Dice coefficient of anat and template masks
3ddot -dodice mask_anat.$subj+tlrc mask_group+tlrc                    \
      |& tee out.mask_at_dice.txt

# ================================= scale ==================================
# scale each voxel time series to have a mean of 100
# (be sure no negatives creep in)
# (subject to a range of [0,200])
foreach run ( $runs )
    3dTstat -prefix rm.mean_r$run pb03.$subj.r$run.blur+tlrc
    3dcalc -a pb03.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \
           -c mask_epi_extents+tlrc                            \
           -expr 'c * min(200, a/b*100)*step(a)*step(b)'       \
           -prefix pb04.$subj.r$run.scale
end

# ================================ regress =================================

# compute de-meaned motion parameters (for use in regression)
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
           -demean -write motion_demean.1D

# compute motion parameter derivatives (just to have)
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
           -derivative -demean -write motion_deriv.1D

# convert motion parameters for per-run regression
1d_tool.py -infile motion_demean.1D -set_nruns 3                         \
           -split_into_pad_runs mot_demean

# create censor file motion_${subj}_censor.1D, for censoring motion 
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
    -show_censor_count -censor_prev_TR                                   \
    -censor_motion 0.3 motion_${subj}

# combine multiple censor files
1deval -a motion_${subj}_censor.1D -b outcount_${subj}_censor.1D         \
       -expr "a*b" > censor_${subj}_combined_2.1D

# note TRs that were not censored
set ktrs = `1d_tool.py -infile censor_${subj}_combined_2.1D              \
                       -show_trs_uncensored encoded`

# ------------------------------
# run the regression analysis
3dDeconvolve -input pb04.$subj.r*.scale+tlrc.HEAD                        \
    -censor censor_${subj}_combined_2.1D                                 \
    -ortvec mot_demean.r01.1D mot_demean_r01                             \
    -ortvec mot_demean.r02.1D mot_demean_r02                             \
    -ortvec mot_demean.r03.1D mot_demean_r03                             \
    -polort 3                                                            \
    -num_stimts 2                                                        \
    -stim_times 1 stimuli/AV1_vis.txt 'BLOCK(20,1)'                      \
    -stim_label 1 vis                                                    \
    -stim_times 2 stimuli/AV2_aud.txt 'BLOCK(20,1)'                      \
    -stim_label 2 aud                                                    \
    -jobs 2                                                              \
    -gltsym 'SYM: vis -aud'                                              \
    -glt_label 1 V-A                                                     \
    -gltsym 'SYM: 0.5*vis +0.5*aud'                                      \
    -glt_label 2 mean.VA                                                 \
    -fout -tout -x1D X.xmat.1D -xjpeg X.jpg                              \
    -x1D_uncensored X.nocensor.xmat.1D                                   \
    -errts errts.${subj}                                                 \
    -bucket stats.$subj


# if 3dDeconvolve fails, terminate the script
if ( $status != 0 ) then
    echo '---------------------------------------'
    echo '** 3dDeconvolve error, failing...'
    echo '   (consider the file 3dDeconvolve.err)'
    exit
endif


# display any large pairwise correlations from the X-matrix
1d_tool.py -show_cormat_warnings -infile X.xmat.1D |& tee out.cormat_warn.txt

# display degrees of freedom info from X-matrix
1d_tool.py -show_df_info -infile X.xmat.1D |& tee out.df_info.txt

# create an all_runs dataset to match the fitts, errts, etc.
3dTcat -prefix all_runs.$subj pb04.$subj.r*.scale+tlrc.HEAD

# --------------------------------------------------
# create a temporal signal to noise ratio dataset 
#    signal: if 'scale' block, mean should be 100
#    noise : compute standard deviation of errts
3dTstat -mean -prefix rm.signal.all all_runs.$subj+tlrc"[$ktrs]"
3dTstat -stdev -prefix rm.noise.all errts.${subj}+tlrc"[$ktrs]"
3dcalc -a rm.signal.all+tlrc                                             \
       -b rm.noise.all+tlrc                                              \
       -expr 'a/b' -prefix TSNR.$subj

# ---------------------------------------------------
# compute and store GCOR (global correlation average)
# (sum of squares of global mean of unit errts)
3dTnorm -norm2 -prefix rm.errts.unit errts.${subj}+tlrc
3dmaskave -quiet -mask full_mask.$subj+tlrc rm.errts.unit+tlrc           \
          > mean.errts.unit.1D
3dTstat -sos -prefix - mean.errts.unit.1D\' > out.gcor.1D
echo "-- GCOR = `cat out.gcor.1D`"

# ---------------------------------------------------
# compute correlation volume
# (per voxel: correlation with masked brain average)
3dmaskave -quiet -mask full_mask.$subj+tlrc errts.${subj}+tlrc           \
          > mean.errts.1D
3dTcorr1D -prefix corr_brain errts.${subj}+tlrc mean.errts.1D

# create fitts dataset from all_runs and errts
3dcalc -a all_runs.$subj+tlrc -b errts.${subj}+tlrc -expr a-b            \
       -prefix fitts.$subj

# create ideal files for fixed response stim types
1dcat X.nocensor.xmat.1D'[12]' > ideal_vis.1D
1dcat X.nocensor.xmat.1D'[13]' > ideal_aud.1D

# --------------------------------------------------
# extract non-baseline regressors from the X-matrix,
# then compute their sum
1d_tool.py -infile X.nocensor.xmat.1D -write_xstim X.stim.xmat.1D
3dTstat -sum -prefix sum_ideal.1D X.stim.xmat.1D

# ============================ blur estimation =============================
# compute blur estimates
touch blur_est.$subj.1D   # start with empty file

# create directory for ACF curve files
mkdir files_ACF

# -- estimate blur for each run in epits --
touch blur.epits.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask mask_epi_anat.$subj+tlrc                      \
            -ACF files_ACF/out.3dFWHMx.ACF.epits.r$run.1D                \
            all_runs.$subj+tlrc"[$trs]" >> blur.epits.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{0..$(2)}'\'` )
echo average epits FWHM blurs: $blurs
echo "$blurs   # epits FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{1..$(2)}'\'` )
echo average epits ACF blurs: $blurs
echo "$blurs   # epits ACF blur estimates" >> blur_est.$subj.1D

# -- estimate blur for each run in errts --
touch blur.errts.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask mask_epi_anat.$subj+tlrc                      \
            -ACF files_ACF/out.3dFWHMx.ACF.errts.r$run.1D                \
            errts.${subj}+tlrc"[$trs]" >> blur.errts.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{0..$(2)}'\'` )
echo average errts FWHM blurs: $blurs
echo "$blurs   # errts FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{1..$(2)}'\'` )
echo average errts ACF blurs: $blurs
echo "$blurs   # errts ACF blur estimates" >> blur_est.$subj.1D


# ========================= auto block: QC_review ==========================
# generate quality control review scripts and HTML report

# generate a review script for the unprocessed EPI data
gen_epi_review.py -script @epi_review.$subj \
    -dsets pb00.$subj.r*.tcat+orig.HEAD

# -------------------------------------------------
# generate scripts to review single subject results
# (try with defaults, but do not allow bad exit status)

# write AP uvars into a simple txt file
cat << EOF > out.ap_uvars.txt
  mot_limit       : 0.3
  out_limit       : 0.05
  copy_anat       : FT_anat+orig.HEAD
  mask_dset       : mask_epi_anat.$subj+tlrc.HEAD
  tlrc_base       : TT_N27+tlrc.HEAD
  ss_review_dset  : out.ss_review.$subj.txt
  vlines_tcat_dir : vlines.pb00.tcat
EOF

# and convert the txt format to JSON
cat out.ap_uvars.txt | afni_python_wrapper.py -eval "data_file_to_json()" \
  > out.ap_uvars.json

# initialize gen_ss_review_scripts.py with out.ap_uvars.json
gen_ss_review_scripts.py -exit0        \
    -init_uvars_json out.ap_uvars.json \
    -write_uvars_json out.ss_review_uvars.json

# ========================== auto block: finalize ==========================

# remove temporary files
\rm -f rm.*

# if the basic subject review script is here, run it
# (want this to be the last text output)
if ( -e @ss_review_basic ) then
    ./@ss_review_basic |& tee out.ss_review.$subj.txt

    # generate html ss review pages
    # (akin to static images from running @ss_review_driver)
    apqc_make_tcsh.py -review_style pythonic -subj_dir . \
        -uvar_json out.ss_review_uvars.json
    tcsh @ss_review_html |& tee out.review_html
    apqc_make_html.py -qc_dir QC_$subj

    echo "\nconsider running: \n"
    echo "   afni_open -b $subj.results/QC_$subj/index.html"
    echo ""
endif

# return to parent directory (just in case...)
cd ..

echo "execution finished: `date`"




# ==========================================================================
# script generated by the command:
#
# afni_proc.py -subj_id FT -blocks tshift align tlrc volreg blur mask scale   \
#     regress -radial_correlate_blocks tcat volreg -copy_anat FT/FT_anat+orig \
#     -dsets FT/FT_epi_r1+orig.HEAD FT/FT_epi_r2+orig.HEAD                    \
#     FT/FT_epi_r3+orig.HEAD -tcat_remove_first_trs 2 -align_unifize_epi      \
#     local -align_opts_aea -cost lpc+ZZ -giant_move -check_flip              \
#     -volreg_align_to MIN_OUTLIER -volreg_align_e2a -volreg_tlrc_warp        \
#     -volreg_compute_tsnr yes -blur_size 4.0 -mask_epi_anat yes              \
#     -regress_stim_times FT/AV1_vis.txt FT/AV2_aud.txt -regress_stim_labels  \
#     vis aud -regress_basis 'BLOCK(20,1)' -regress_censor_motion 0.3         \
#     -regress_censor_outliers 0.05 -regress_motion_per_run -regress_opts_3dD \
#     -jobs 2 -gltsym 'SYM: vis -aud' -glt_label 1 V-A -gltsym 'SYM: 0.5*vis  \
#     +0.5*aud' -glt_label 2 mean.VA -regress_compute_fitts                   \
#     -regress_make_ideal_sum sum_ideal.1D -regress_est_blur_epits            \
#     -regress_est_blur_errts -regress_run_clustsim no -html_review_style     \
#     pythonic -execute


















###########################
##### FULL TCSH SCRIPT ####
###########################


#!/bin/tcsh -xef

echo "auto-generated by afni_proc.py, Tue Jan 31 15:45:04 2023"
echo "(version 7.51, January 24, 2023)"
echo "execution started: `date`"

# to execute via tcsh: 
#   tcsh -xef proc.FT |& tee output.proc.FT
# to execute via bash: 
#   tcsh -xef proc.FT 2>&1 | tee output.proc.FT

# =========================== auto block: setup ============================
# script setup

# take note of the AFNI version
afni -ver

# check that the current AFNI version is recent enough
afni_history -check_date 14 Nov 2022
if ( $status ) then
    echo "** this script requires newer AFNI binaries (than 14 Nov 2022)"
    echo "   (consider: @update.afni.binaries -defaults)"
    exit
endif

# the user may specify a single subject to run with
if ( $#argv > 0 ) then
    set subj = $argv[1]
else
    set subj = FT
endif

# assign output directory name
set output_dir = $subj.results

# verify that the results directory does not yet exist
if ( -d $output_dir ) then
    echo output dir "$subj.results" already exists
    exit
endif

# set list of runs
set runs = (`count -digits 2 1 3`)

# create results and stimuli directories
mkdir -p $output_dir
mkdir $output_dir/stimuli

# copy stim files into stimulus directory
cp FT/AV1_vis.txt FT/AV2_aud.txt $output_dir/stimuli

# copy anatomy to results dir
3dcopy FT/FT_anat+orig $output_dir/FT_anat

# copy template to results dir (for QC)
3dcopy /home/jlefortb/abin/TT_N27+tlrc.HEAD $output_dir/TT_N27+tlrc.HEAD

# ============================ auto block: tcat ============================
# apply 3dTcat to copy input dsets to results dir,
# while removing the first 2 TRs
3dTcat -prefix $output_dir/pb00.$subj.r01.tcat FT/FT_epi_r1+orig'[2..$]'
3dTcat -prefix $output_dir/pb00.$subj.r02.tcat FT/FT_epi_r2+orig'[2..$]'
3dTcat -prefix $output_dir/pb00.$subj.r03.tcat FT/FT_epi_r3+orig'[2..$]'

# and make note of repetitions (TRs) per run
set tr_counts = ( 150 150 150 )

# -------------------------------------------------------
# enter the results directory (can begin processing data)
cd $output_dir


# ---------------------------------------------------------
# QC: compute correlations with spherical ~averages
@radial_correlate -nfirst 0 -polort 3 -do_clean yes \
                  -rdir radcor.pb00.tcat            \
                  pb00.$subj.r*.tcat+orig.HEAD

# ---------------------------------------------------------
# QC: look for columns of high variance
find_variance_lines.tcsh -polort 3 -nerode 2        \
       -rdir vlines.pb00.tcat                       \
       pb00.$subj.r*.tcat+orig.HEAD |& tee out.vlines.pb00.tcat.txt

# ========================== auto block: outcount ==========================
# QC: compute outlier fraction for each volume
touch out.pre_ss_warn.txt
foreach run ( $runs )
    3dToutcount -automask -fraction -polort 3 -legendre                     \
                pb00.$subj.r$run.tcat+orig > outcount.r$run.1D

    # censor outlier TRs per run, ignoring the first 0 TRs
    # - censor when more than 0.05 of automask voxels are outliers
    # - step() defines which TRs to remove via censoring
    1deval -a outcount.r$run.1D -expr "1-step(a-0.05)" > rm.out.cen.r$run.1D

    # outliers at TR 0 might suggest pre-steady state TRs
    if ( `1deval -a outcount.r$run.1D"{0}" -expr "step(a-0.4)"` ) then
        echo "** TR #0 outliers: possible pre-steady state TRs in run $run" \
            >> out.pre_ss_warn.txt
    endif
end

# catenate outlier counts into a single time series
cat outcount.r*.1D > outcount_rall.1D

# catenate outlier censor files into a single time series
cat rm.out.cen.r*.1D > outcount_${subj}_censor.1D

# get run number and TR index for minimum outlier volume
set minindex = `3dTstat -argmin -prefix - outcount_rall.1D\'`
set ovals = ( `1d_tool.py -set_run_lengths $tr_counts                       \
                          -index_to_run_tr $minindex` )
# save run and TR indices for extraction of vr_base_min_outlier
set minoutrun = $ovals[1]
set minouttr  = $ovals[2]
echo "min outlier: run $minoutrun, TR $minouttr" | tee out.min_outlier.txt

# ================================= tshift =================================
# time shift data so all slice timing is the same 
foreach run ( $runs )
    3dTshift -tzero 0 -quintic -prefix pb01.$subj.r$run.tshift \
             pb00.$subj.r$run.tcat+orig
end

# --------------------------------
# extract volreg registration base
3dbucket -prefix vr_base_min_outlier                           \
    pb01.$subj.r$minoutrun.tshift+orig"[$minouttr]"

# ================================= align ==================================
# for e2a: compute anat alignment transformation to EPI registration base
# (new anat will be intermediate, stripped, FT_anat_ns+orig)
# run (localized) uniformity correction on EPI base
3dLocalUnifize -input vr_base_min_outlier+orig -prefix \
    vr_base_min_outlier_unif

align_epi_anat.py -anat2epi -anat FT_anat+orig         \
       -save_skullstrip -suffix _al_junk               \
       -epi vr_base_min_outlier_unif+orig -epi_base 0  \
       -epi_strip 3dAutomask                           \
       -cost lpc+ZZ -giant_move -check_flip            \
       -volreg off -tshift off

# ================================== tlrc ==================================
# warp anatomy to standard space
@auto_tlrc -base TT_N27+tlrc -input FT_anat_ns+orig -no_ss

# store forward transformation matrix in a text file
cat_matvec FT_anat_ns+tlrc::WARP_DATA -I > warp.anat.Xat.1D

# ================================= volreg =================================
# align each dset to base volume, to anat, warp to tlrc space

# verify that we have a +tlrc warp dataset
if ( ! -f FT_anat_ns+tlrc.HEAD ) then
    echo "** missing +tlrc warp dataset: FT_anat_ns+tlrc.HEAD" 
    exit
endif

# register and warp
foreach run ( $runs )
    # register each volume to the base image
    3dvolreg -verbose -zpad 1 -base vr_base_min_outlier+orig    \
             -1Dfile dfile.r$run.1D -prefix rm.epi.volreg.r$run \
             -cubic                                             \
             -1Dmatrix_save mat.r$run.vr.aff12.1D               \
             pb01.$subj.r$run.tshift+orig

    # create an all-1 dataset to mask the extents of the warp
    3dcalc -overwrite -a pb01.$subj.r$run.tshift+orig -expr 1   \
           -prefix rm.epi.all1

    # catenate volreg/epi2anat/tlrc xforms
    cat_matvec -ONELINE                                         \
               FT_anat_ns+tlrc::WARP_DATA -I                    \
               FT_anat_al_junk_mat.aff12.1D -I                  \
               mat.r$run.vr.aff12.1D > mat.r$run.warp.aff12.1D

    # apply catenated xform: volreg/epi2anat/tlrc
    3dAllineate -base FT_anat_ns+tlrc                           \
                -input pb01.$subj.r$run.tshift+orig             \
                -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
                -mast_dxyz 2.5                                  \
                -prefix rm.epi.nomask.r$run

    # warp the all-1 dataset for extents masking 
    3dAllineate -base FT_anat_ns+tlrc                           \
                -input rm.epi.all1+orig                         \
                -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
                -mast_dxyz 2.5 -final NN -quiet                 \
                -prefix rm.epi.1.r$run

    # make an extents intersection mask of this run
    3dTstat -min -prefix rm.epi.min.r$run rm.epi.1.r$run+tlrc
end

# make a single file of registration params
cat dfile.r*.1D > dfile_rall.1D

# ----------------------------------------
# create the extents mask: mask_epi_extents+tlrc
# (this is a mask of voxels that have valid data at every TR)
3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD 
3dcalc -a rm.epi.mean+tlrc -expr 'step(a-0.999)' -prefix mask_epi_extents

# and apply the extents mask to the EPI data 
# (delete any time series with missing data)
foreach run ( $runs )
    3dcalc -a rm.epi.nomask.r$run+tlrc -b mask_epi_extents+tlrc \
           -expr 'a*b' -prefix pb02.$subj.r$run.volreg
end

# warp the volreg base EPI dataset to make a final version
cat_matvec -ONELINE                                             \
           FT_anat_ns+tlrc::WARP_DATA -I                        \
           FT_anat_al_junk_mat.aff12.1D -I  > mat.basewarp.aff12.1D

3dAllineate -base FT_anat_ns+tlrc                               \
            -input vr_base_min_outlier+orig                     \
            -1Dmatrix_apply mat.basewarp.aff12.1D               \
            -mast_dxyz 2.5                                      \
            -prefix final_epi_vr_base_min_outlier

# create an anat_final dataset, aligned with stats
3dcopy FT_anat_ns+tlrc anat_final.$subj

# record final registration costs
3dAllineate -base final_epi_vr_base_min_outlier+tlrc -allcostX  \
            -input anat_final.$subj+tlrc |& tee out.allcostX.txt

# --------------------------------------
# create a TSNR dataset, just from run 1
3dTstat -mean -prefix rm.signal.vreg.r01 pb02.$subj.r01.volreg+tlrc
3dDetrend -polort 3 -prefix rm.noise.det -overwrite pb02.$subj.r01.volreg+tlrc
3dTstat -stdev -prefix rm.noise.vreg.r01 rm.noise.det+tlrc
3dcalc -a rm.signal.vreg.r01+tlrc                               \
       -b rm.noise.vreg.r01+tlrc                                \
       -c mask_epi_extents+tlrc                                 \
       -expr 'c*a/b' -prefix TSNR.vreg.r01.$subj

# -----------------------------------------
# warp anat follower datasets (affine)
# warp follower dataset FT_anat+orig
3dAllineate -source FT_anat+orig                                \
            -master anat_final.$subj+tlrc                       \
            -final wsinc5 -1Dmatrix_apply warp.anat.Xat.1D      \
            -prefix anat_w_skull_warped

# ---------------------------------------------------------
# QC: compute correlations with spherical ~averages
@radial_correlate -nfirst 0 -polort 3 -do_clean yes             \
                  -rdir radcor.pb02.volreg                      \
                  pb02.$subj.r*.volreg+tlrc.HEAD

# ================================== blur ==================================
# blur each volume of each run
foreach run ( $runs )
    3dmerge -1blur_fwhm 4.0 -doall -prefix pb03.$subj.r$run.blur \
            pb02.$subj.r$run.volreg+tlrc
end

# ================================== mask ==================================
# create 'full_mask' dataset (union mask)
foreach run ( $runs )
    3dAutomask -prefix rm.mask_r$run pb03.$subj.r$run.blur+tlrc
end

# create union of inputs, output type is byte
3dmask_tool -inputs rm.mask_r*+tlrc.HEAD -union -prefix full_mask.$subj

# ---- create subject anatomy mask, mask_anat.$subj+tlrc ----
#      (resampled from tlrc anat)
3dresample -master full_mask.$subj+tlrc -input FT_anat_ns+tlrc        \
           -prefix rm.resam.anat

# convert to binary anat mask; fill gaps and holes
3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.anat+tlrc  \
            -prefix mask_anat.$subj

# compute tighter EPI mask by intersecting with anat mask
3dmask_tool -input full_mask.$subj+tlrc mask_anat.$subj+tlrc          \
            -inter -prefix mask_epi_anat.$subj

# compute overlaps between anat and EPI masks
3dABoverlap -no_automask full_mask.$subj+tlrc mask_anat.$subj+tlrc    \
            |& tee out.mask_ae_overlap.txt

# note Dice coefficient of masks, as well
3ddot -dodice full_mask.$subj+tlrc mask_anat.$subj+tlrc               \
      |& tee out.mask_ae_dice.txt

# ---- create group anatomy mask, mask_group+tlrc ----
#      (resampled from tlrc base anat, TT_N27+tlrc)
3dresample -master full_mask.$subj+tlrc -prefix ./rm.resam.group      \
           -input /home/jlefortb/abin/TT_N27+tlrc

# convert to binary group mask; fill gaps and holes
3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.group+tlrc \
            -prefix mask_group

# note Dice coefficient of anat and template masks
3ddot -dodice mask_anat.$subj+tlrc mask_group+tlrc                    \
      |& tee out.mask_at_dice.txt

# ================================= scale ==================================
# scale each voxel time series to have a mean of 100
# (be sure no negatives creep in)
# (subject to a range of [0,200])
foreach run ( $runs )
    3dTstat -prefix rm.mean_r$run pb03.$subj.r$run.blur+tlrc
    3dcalc -a pb03.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \
           -c mask_epi_extents+tlrc                            \
           -expr 'c * min(200, a/b*100)*step(a)*step(b)'       \
           -prefix pb04.$subj.r$run.scale
end

# ================================ regress =================================

# compute de-meaned motion parameters (for use in regression)
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
           -demean -write motion_demean.1D

# compute motion parameter derivatives (just to have)
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
           -derivative -demean -write motion_deriv.1D

# convert motion parameters for per-run regression
1d_tool.py -infile motion_demean.1D -set_nruns 3                         \
           -split_into_pad_runs mot_demean

# create censor file motion_${subj}_censor.1D, for censoring motion 
1d_tool.py -infile dfile_rall.1D -set_nruns 3                            \
    -show_censor_count -censor_prev_TR                                   \
    -censor_motion 0.3 motion_${subj}

# combine multiple censor files
1deval -a motion_${subj}_censor.1D -b outcount_${subj}_censor.1D         \
       -expr "a*b" > censor_${subj}_combined_2.1D

# note TRs that were not censored
set ktrs = `1d_tool.py -infile censor_${subj}_combined_2.1D              \
                       -show_trs_uncensored encoded`

# ------------------------------
# run the regression analysis
3dDeconvolve -input pb04.$subj.r*.scale+tlrc.HEAD                        \
    -censor censor_${subj}_combined_2.1D                                 \
    -ortvec mot_demean.r01.1D mot_demean_r01                             \
    -ortvec mot_demean.r02.1D mot_demean_r02                             \
    -ortvec mot_demean.r03.1D mot_demean_r03                             \
    -polort 3                                                            \
    -num_stimts 2                                                        \
    -stim_times 1 stimuli/AV1_vis.txt 'BLOCK(20,1)'                      \
    -stim_label 1 vis                                                    \
    -stim_times 2 stimuli/AV2_aud.txt 'BLOCK(20,1)'                      \
    -stim_label 2 aud                                                    \
    -jobs 2                                                              \
    -gltsym 'SYM: vis -aud'                                              \
    -glt_label 1 V-A                                                     \
    -gltsym 'SYM: 0.5*vis +0.5*aud'                                      \
    -glt_label 2 mean.VA                                                 \
    -fout -tout -x1D X.xmat.1D -xjpeg X.jpg                              \
    -x1D_uncensored X.nocensor.xmat.1D                                   \
    -errts errts.${subj}                                                 \
    -bucket stats.$subj


# if 3dDeconvolve fails, terminate the script
if ( $status != 0 ) then
    echo '---------------------------------------'
    echo '** 3dDeconvolve error, failing...'
    echo '   (consider the file 3dDeconvolve.err)'
    exit
endif


# display any large pairwise correlations from the X-matrix
1d_tool.py -show_cormat_warnings -infile X.xmat.1D |& tee out.cormat_warn.txt

# display degrees of freedom info from X-matrix
1d_tool.py -show_df_info -infile X.xmat.1D |& tee out.df_info.txt

# create an all_runs dataset to match the fitts, errts, etc.
3dTcat -prefix all_runs.$subj pb04.$subj.r*.scale+tlrc.HEAD

# --------------------------------------------------
# create a temporal signal to noise ratio dataset 
#    signal: if 'scale' block, mean should be 100
#    noise : compute standard deviation of errts
3dTstat -mean -prefix rm.signal.all all_runs.$subj+tlrc"[$ktrs]"
3dTstat -stdev -prefix rm.noise.all errts.${subj}+tlrc"[$ktrs]"
3dcalc -a rm.signal.all+tlrc                                             \
       -b rm.noise.all+tlrc                                              \
       -expr 'a/b' -prefix TSNR.$subj

# ---------------------------------------------------
# compute and store GCOR (global correlation average)
# (sum of squares of global mean of unit errts)
3dTnorm -norm2 -prefix rm.errts.unit errts.${subj}+tlrc
3dmaskave -quiet -mask full_mask.$subj+tlrc rm.errts.unit+tlrc           \
          > mean.errts.unit.1D
3dTstat -sos -prefix - mean.errts.unit.1D\' > out.gcor.1D
echo "-- GCOR = `cat out.gcor.1D`"

# ---------------------------------------------------
# compute correlation volume
# (per voxel: correlation with masked brain average)
3dmaskave -quiet -mask full_mask.$subj+tlrc errts.${subj}+tlrc           \
          > mean.errts.1D
3dTcorr1D -prefix corr_brain errts.${subj}+tlrc mean.errts.1D

# create fitts dataset from all_runs and errts
3dcalc -a all_runs.$subj+tlrc -b errts.${subj}+tlrc -expr a-b            \
       -prefix fitts.$subj

# create ideal files for fixed response stim types
1dcat X.nocensor.xmat.1D'[12]' > ideal_vis.1D
1dcat X.nocensor.xmat.1D'[13]' > ideal_aud.1D

# --------------------------------------------------
# extract non-baseline regressors from the X-matrix,
# then compute their sum
1d_tool.py -infile X.nocensor.xmat.1D -write_xstim X.stim.xmat.1D
3dTstat -sum -prefix sum_ideal.1D X.stim.xmat.1D

# ============================ blur estimation =============================
# compute blur estimates
touch blur_est.$subj.1D   # start with empty file

# create directory for ACF curve files
mkdir files_ACF

# -- estimate blur for each run in epits --
touch blur.epits.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask mask_epi_anat.$subj+tlrc                      \
            -ACF files_ACF/out.3dFWHMx.ACF.epits.r$run.1D                \
            all_runs.$subj+tlrc"[$trs]" >> blur.epits.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{0..$(2)}'\'` )
echo average epits FWHM blurs: $blurs
echo "$blurs   # epits FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{1..$(2)}'\'` )
echo average epits ACF blurs: $blurs
echo "$blurs   # epits ACF blur estimates" >> blur_est.$subj.1D

# -- estimate blur for each run in errts --
touch blur.errts.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask mask_epi_anat.$subj+tlrc                      \
            -ACF files_ACF/out.3dFWHMx.ACF.errts.r$run.1D                \
            errts.${subj}+tlrc"[$trs]" >> blur.errts.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{0..$(2)}'\'` )
echo average errts FWHM blurs: $blurs
echo "$blurs   # errts FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{1..$(2)}'\'` )
echo average errts ACF blurs: $blurs
echo "$blurs   # errts ACF blur estimates" >> blur_est.$subj.1D


# ========================= auto block: QC_review ==========================
# generate quality control review scripts and HTML report

# generate a review script for the unprocessed EPI data
gen_epi_review.py -script @epi_review.$subj \
    -dsets pb00.$subj.r*.tcat+orig.HEAD

# -------------------------------------------------
# generate scripts to review single subject results
# (try with defaults, but do not allow bad exit status)

# write AP uvars into a simple txt file
cat << EOF > out.ap_uvars.txt
  mot_limit       : 0.3
  out_limit       : 0.05
  copy_anat       : FT_anat+orig.HEAD
  mask_dset       : mask_epi_anat.$subj+tlrc.HEAD
  tlrc_base       : TT_N27+tlrc.HEAD
  ss_review_dset  : out.ss_review.$subj.txt
  vlines_tcat_dir : vlines.pb00.tcat
EOF

# and convert the txt format to JSON
cat out.ap_uvars.txt | afni_python_wrapper.py -eval "data_file_to_json()" \
  > out.ap_uvars.json

# initialize gen_ss_review_scripts.py with out.ap_uvars.json
gen_ss_review_scripts.py -exit0        \
    -init_uvars_json out.ap_uvars.json \
    -write_uvars_json out.ss_review_uvars.json

# ========================== auto block: finalize ==========================

# remove temporary files
\rm -f rm.*

# if the basic subject review script is here, run it
# (want this to be the last text output)
if ( -e @ss_review_basic ) then
    ./@ss_review_basic |& tee out.ss_review.$subj.txt

    # generate html ss review pages
    # (akin to static images from running @ss_review_driver)
    apqc_make_tcsh.py -review_style pythonic -subj_dir . \
        -uvar_json out.ss_review_uvars.json
    tcsh @ss_review_html |& tee out.review_html
    apqc_make_html.py -qc_dir QC_$subj

    echo "\nconsider running: \n"
    echo "   afni_open -b $subj.results/QC_$subj/index.html"
    echo ""
endif

# return to parent directory (just in case...)
cd ..

echo "execution finished: `date`"




# ==========================================================================
# script generated by the command:
#
# afni_proc.py -subj_id FT -blocks tshift align tlrc volreg blur mask scale   \
#     regress -radial_correlate_blocks tcat volreg -copy_anat FT/FT_anat+orig \
#     -dsets FT/FT_epi_r1+orig.HEAD FT/FT_epi_r2+orig.HEAD                    \
#     FT/FT_epi_r3+orig.HEAD -tcat_remove_first_trs 2 -align_unifize_epi      \
#     local -align_opts_aea -cost lpc+ZZ -giant_move -check_flip              \
#     -volreg_align_to MIN_OUTLIER -volreg_align_e2a -volreg_tlrc_warp        \
#     -volreg_compute_tsnr yes -blur_size 4.0 -mask_epi_anat yes              \
#     -regress_stim_times FT/AV1_vis.txt FT/AV2_aud.txt -regress_stim_labels  \
#     vis aud -regress_basis 'BLOCK(20,1)' -regress_censor_motion 0.3         \
#     -regress_censor_outliers 0.05 -regress_motion_per_run -regress_opts_3dD \
#     -jobs 2 -gltsym 'SYM: vis -aud' -glt_label 1 V-A -gltsym 'SYM: 0.5*vis  \
#     +0.5*aud' -glt_label 2 mean.VA -regress_compute_fitts                   \
#     -regress_make_ideal_sum sum_ideal.1D -regress_est_blur_epits            \
#     -regress_est_blur_errts -regress_run_clustsim no -html_review_style     \
#     pythonic -execute

